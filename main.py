RANDOM_SEED = 42
BATCH_SIZE = 2 # number of samples propogated
EPOCHS = 40 # number of iterations of training dataset

LEARNING_RATE = 1e-4
NUM_CLASSES = 10
PATCH_SIZE = 4
IMG_SIZE = 28
INPUT_CHANNELS = 1
NUM_HEADS = 8 # DECIDES HOW MANY ATTENTION HEADS WE WILL USE
DROPOUT = 0.001
HIDDEN_DIMENSION = 768 # HIDDEN DIMENSION OF MLP HEAD
ADAM_WEIGHT_DECAY = 0 # WEIGHT DECAY WE WILL GIVE TO THE OPTIMIZER, IN THE PAPER THE VALUE DOES NOT WORK AS WELL
ADAM_BETAS = (0.9, 0.999)
ACTIVATION = "gelu"
NUMBER_ENCODERS = 4
EMBEDDED_DIMENSION = (PATCH_SIZE ** 2) * INPUT_CHANNELS # 16
NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2 # 49

random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
torch.cuda.manual_seed(RANDOM_SEED)
torch.cuda.manual_seed_all(RANDOM_SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False